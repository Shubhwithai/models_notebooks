{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://drive.google.com/uc?export=view&id=1wYSMgJtARFdvTt5g7E20mE4NmwUFUuog\" width=\"200\">\n",
    "\n",
    "[![Gen AI Experiments](https://img.shields.io/badge/Gen%20AI%20Experiments-GenAI%20Bootcamp-blue?style=for-the-badge&logo=artificial-intelligence)](https://github.com/buildfastwithai/gen-ai-experiments)\n",
    "[![Gen AI Experiments GitHub](https://img.shields.io/github/stars/buildfastwithai/gen-ai-experiments?style=for-the-badge&logo=github&color=gold)](http://github.com/buildfastwithai/gen-ai-experiments)\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/[NOTEBOOK_ID])\n",
    "\n",
    "## Master Generative AI in 8 Weeks\n",
    "**What You'll Learn:**\n",
    "- Master cutting-edge AI tools & frameworks\n",
    "- 6 weeks of hands-on, project-based learning\n",
    "- Weekly live mentorship sessions\n",
    "- No coding experience required\n",
    "- Join Innovation Community\n",
    "\n",
    "Transform your AI ideas into reality through hands-on projects and expert mentorship.\n",
    "\n",
    "[Start Your Journey](https://www.buildfastwithai.com/genai-course)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPT 5.1 - Testing & Basics\n",
    "\n",
    "**Created by:** @BuildFastWithAI  \n",
    "**Model:** OpenAI GPT 5.1  \n",
    "**Last Updated:** November 2025\n",
    "\n",
    "This notebook covers the fundamentals of working with GPT 5.1, including:\n",
    "- Basic setup and hello world examples\n",
    "- Tool calling capabilities\n",
    "- Simple agent implementation\n",
    "- Quick RAG demo\n",
    "- Performance metrics and cost estimates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup & Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q openai langchain langchain-openai faiss-cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from google.colab import userdata\n",
    "import time\n",
    "import json\n",
    "\n",
    "# Configure API key from Colab secrets\n",
    "try:\n",
    "    OPENAI_API_KEY = userdata.get('OPENAI_API_KEY')\n",
    "    client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "    print(\"‚úÖ API key configured successfully\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error: {e}\")\n",
    "    print(\"Please add OPENAI_API_KEY to Colab secrets\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Basic Example - Hello World"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple generation\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-5.1\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"Hello! Introduce yourself and explain what makes you unique.\"}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with parameters\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-5.1\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"Write a creative short story about AI in 3 sentences.\"}\n",
    "    ],\n",
    "    temperature=0.9,\n",
    "    max_tokens=200,\n",
    "    top_p=0.95\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Tool Calling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define tools\n",
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"get_weather\",\n",
    "            \"description\": \"Get weather information for a location\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"location\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"City name or location\"\n",
    "                    },\n",
    "                    \"unit\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"enum\": [\"celsius\", \"fahrenheit\"],\n",
    "                        \"description\": \"Temperature unit\"\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"location\"]\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"calculator\",\n",
    "            \"description\": \"Perform arithmetic operations\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"operation\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"enum\": [\"add\", \"subtract\", \"multiply\", \"divide\"]\n",
    "                    },\n",
    "                    \"num1\": {\"type\": \"number\"},\n",
    "                    \"num2\": {\"type\": \"number\"}\n",
    "                },\n",
    "                \"required\": [\"operation\", \"num1\", \"num2\"]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "# Function implementations\n",
    "def get_weather(location, unit=\"fahrenheit\"):\n",
    "    return {\"location\": location, \"temperature\": 72, \"condition\": \"Sunny\", \"unit\": unit}\n",
    "\n",
    "def calculator(operation, num1, num2):\n",
    "    ops = {\n",
    "        \"add\": num1 + num2,\n",
    "        \"subtract\": num1 - num2,\n",
    "        \"multiply\": num1 * num2,\n",
    "        \"divide\": num1 / num2 if num2 != 0 else \"Error\"\n",
    "    }\n",
    "    return ops.get(operation, \"Invalid\")\n",
    "\n",
    "# Test tool calling\n",
    "messages = [{\"role\": \"user\", \"content\": \"What's the weather in Paris and what is 25 * 4?\"}]\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-5.1\",\n",
    "    messages=messages,\n",
    "    tools=tools,\n",
    "    tool_choice=\"auto\"\n",
    ")\n",
    "\n",
    "print(response.choices[0].message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Simple Agent Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleAgent:\n",
    "    def __init__(self, model=\"gpt-5.1\"):\n",
    "        self.model = model\n",
    "        self.client = client\n",
    "        self.tools = tools\n",
    "        self.tool_map = {\n",
    "            \"get_weather\": get_weather,\n",
    "            \"calculator\": calculator\n",
    "        }\n",
    "    \n",
    "    def run(self, query: str, max_iterations: int = 5):\n",
    "        messages = [{\"role\": \"user\", \"content\": query}]\n",
    "        \n",
    "        for i in range(max_iterations):\n",
    "            response = self.client.chat.completions.create(\n",
    "                model=self.model,\n",
    "                messages=messages,\n",
    "                tools=self.tools,\n",
    "                tool_choice=\"auto\"\n",
    "            )\n",
    "            \n",
    "            message = response.choices[0].message\n",
    "            \n",
    "            # Check for tool calls\n",
    "            if message.tool_calls:\n",
    "                messages.append(message)\n",
    "                \n",
    "                for tool_call in message.tool_calls:\n",
    "                    func_name = tool_call.function.name\n",
    "                    func_args = json.loads(tool_call.function.arguments)\n",
    "                    \n",
    "                    print(f\"üîß Calling: {func_name}({func_args})\")\n",
    "                    \n",
    "                    result = self.tool_map[func_name](**func_args)\n",
    "                    print(f\"   Result: {result}\\n\")\n",
    "                    \n",
    "                    messages.append({\n",
    "                        \"role\": \"tool\",\n",
    "                        \"tool_call_id\": tool_call.id,\n",
    "                        \"content\": json.dumps(result)\n",
    "                    })\n",
    "            else:\n",
    "                print(f\"Final Answer: {message.content}\")\n",
    "                return message.content\n",
    "        \n",
    "        return \"Max iterations reached\"\n",
    "\n",
    "# Test agent\n",
    "agent = SimpleAgent()\n",
    "result = agent.run(\"What's the weather in Tokyo and calculate 100 divided by 4?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Quick RAG Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "# Sample documents\n",
    "documents = [\n",
    "    \"GPT 5.1 is OpenAI's latest large language model with enhanced reasoning capabilities.\",\n",
    "    \"The model supports advanced function calling and structured output generation.\",\n",
    "    \"GPT 5.1 offers improved context understanding and can handle complex multi-step tasks.\",\n",
    "    \"It features state-of-the-art performance on coding and mathematical reasoning.\",\n",
    "    \"The model is optimized for both quality and efficiency in production environments.\"\n",
    "]\n",
    "\n",
    "# Create embeddings and vector store\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=200, chunk_overlap=50)\n",
    "texts = text_splitter.create_documents(documents)\n",
    "\n",
    "vectorstore = FAISS.from_documents(texts, embeddings)\n",
    "\n",
    "# Create QA chain\n",
    "llm = ChatOpenAI(model=\"gpt-5.1\", temperature=0.3)\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=vectorstore.as_retriever(search_kwargs={\"k\": 3})\n",
    ")\n",
    "\n",
    "# Query\n",
    "query = \"What are the key features of GPT 5.1?\"\n",
    "response = qa_chain.run(query)\n",
    "print(f\"Question: {query}\")\n",
    "print(f\"\\nAnswer: {response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Use Cases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Customer Support Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-5.1\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful customer support agent.\"},\n",
    "        {\"role\": \"user\", \"content\": \"I can't log into my account. What should I do?\"}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code Assistant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-5.1\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"Write a Python function to find the nth Fibonacci number with memoization.\"}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    \"sales\": [1000, 1500, 1200, 1800, 2000],\n",
    "    \"months\": [\"Jan\", \"Feb\", \"Mar\", \"Apr\", \"May\"]\n",
    "}\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-5.1\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": f\"Analyze this sales data and provide insights: {json.dumps(data)}\"}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Performance Metrics & Cost Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Benchmark\n",
    "test_prompts = [\n",
    "    \"What is machine learning?\",\n",
    "    \"Explain quantum computing in simple terms.\",\n",
    "    \"Write a haiku about AI.\"\n",
    "]\n",
    "\n",
    "total_time = 0\n",
    "total_tokens = 0\n",
    "\n",
    "for prompt in test_prompts:\n",
    "    start = time.time()\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-5.1\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "    elapsed = time.time() - start\n",
    "    total_time += elapsed\n",
    "    \n",
    "    tokens = response.usage.total_tokens\n",
    "    total_tokens += tokens\n",
    "    \n",
    "    print(f\"Prompt: {prompt[:50]}...\")\n",
    "    print(f\"Time: {elapsed:.2f}s | Tokens: {tokens}\\n\")\n",
    "\n",
    "print(f\"\\nüìä Summary:\")\n",
    "print(f\"Total Time: {total_time:.2f}s\")\n",
    "print(f\"Average Time: {total_time/len(test_prompts):.2f}s\")\n",
    "print(f\"Total Tokens: {total_tokens}\")\n",
    "print(f\"\\nüí∞ Estimated Cost (at $0.002/1K tokens): ${(total_tokens/1000) * 0.002:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Key Takeaways\n",
    "\n",
    "‚úÖ **Strengths:**\n",
    "- Exceptional reasoning capabilities\n",
    "- Advanced function calling\n",
    "- Strong performance on complex tasks\n",
    "- Excellent code generation\n",
    "\n",
    "üìå **Best Practices:**\n",
    "- Use Colab secrets for API keys\n",
    "- Implement error handling\n",
    "- Monitor token usage and costs\n",
    "- Test with different temperature settings\n",
    "\n",
    "üîó **Resources:**\n",
    "- [OpenAI Documentation](https://platform.openai.com/docs)\n",
    "- [API Reference](https://platform.openai.com/docs/api-reference)\n",
    "- Follow [@BuildFastWithAI](https://twitter.com/BuildFastWithAI) for more tutorials"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
